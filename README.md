# ğŸ§  RAG Agentic Knowledge Assistant (Demo)

This is a Retrieval-Augmented Generation (RAG) + AgentKit demo for regulated industries.  
It combines **FastAPI**, **Chroma**, **OCR**, and **OpenAI models** to power a secure knowledge assistant with agentic reasoning capabilities.

The stack is designed to run locally and includes:
- âœ… **FastAPI Backend** with ingestion, retrieval, OCR, and RAG
- âœ… **Next.js Frontend** with simple chat + file upload UI
- âœ… **OCR support** (Tesseract + Poppler) for scanned PDFs
- âœ… Integration of **CSV + PDF** data sources into Chroma vector DB
- âœ… **AgentKit** integration for multi-step reasoning (Agentic behavior)
- âœ… **Dockerized**, easy to run anywhere

## ğŸš€ Testing the setup

```
FE:
1. npm install && npm run build
2. npm run start
3. Visit http://localhost:3000

BE:
1. cd backend/
2. uvicorn app:app --host 0.0.0.0 --port $PORT
3. Upload a sample .pdf, .docx, .txt or .csv
4. Ask a question in the chat box
5. Verify answer and citations appear

```

## ğŸ§± Project Structure

```
rag_agentic_assistant/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ routers/
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ pdfs/
â”‚   â””â”€â”€ csv/
â”‚   â””â”€â”€ docx/
â”‚   â””â”€â”€ txt/
â”œâ”€â”€ index_store/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env
â””â”€â”€ README.md
```

## ğŸš€ Features

- **RAG Backend**
  - FastAPI endpoints for PDF/CSV ingestion, search, chat
  - Uses `text-embedding-3-small` for embeddings and `gpt-4o-mini` for answers
  - Chroma as vector store
  - Auto-OCR for scanned PDFs

- **Frontend**
  - Next.j UI with chat box + file upload
  - Bearer token auth
  - Shows citations and metadata

- **Agentic Mode**
  - Leverages [OpenAI AgentKit](https://openai.com/index/introducing-agentkit/) to enable multi-step reasoning.

## âš¡ï¸ Prerequisites

- OpenAI API Key with access to `gpt-4o-mini` and embeddings
- Tesseract and Poppler are installed inside the container

## ğŸ§° Environment Variables

Create a `.env` file in the project root:

```env
# Backend
OPENAI_API_KEY=sk-your-key
ANSWER_MODEL=gpt-4o-mini
EMBED_MODEL=text-embedding-3-small
BEARER_TOKEN=your-demo-token

DATA_DIR=/app/data
INDEX_DIR=/app/index_store/chroma_db

# Frontend
NEXT_PUBLIC_API_BASE=http://localhost:8000/api
NEXT_PUBLIC_BEARER_TOKEN=your-demo-token
```

- Backend â†’ http://localhost:8000
- Frontend â†’ http://localhost:3000

## ğŸ“¥ Ingesting Data

Upload via UI 

## ğŸ’¬ Asking Questions

```bash
curl -X POST "http://localhost:8000/api/chat"   -H "Authorization: Bearer your-demo-token"   -H "Content-Type: application/json"   -d '{"query":"What are the encryption requirements?"}'
```

## ğŸ“ Example Queries

- â€œWhat new regulatory measures have been introduced in the EU for digital banking in 2025?â€  
- â€œWhen do the KYC policy changes become effective?â€

## ğŸ“„ License

Demo project for client delivery. Not for redistribution.